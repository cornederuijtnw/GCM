{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"/Users/cornederuijt/github/GCM/\") # Adjust after construction of the package\n",
    "\n",
    "from scripts.clickmodel_fitters.clickdefinitionreader import ClickDefinition\n",
    "from scripts.clickmodel_fitters.GCM import GCM\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "np.random.seed(1992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDense(Layer):\n",
    "    def __init__(self, units=11):\n",
    "        super(SimpleDense, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):  # Create the state of the layer (weights)\n",
    "        T = self.units - 1  # As we exclude the zero state for now\n",
    "        zero_init = tf.zeros_initializer()\n",
    "\n",
    "        self._w = tf.Variable(initial_value=zero_init(shape=(int(T * (T + 1) / 2),), dtype='float32'), trainable=True)\n",
    "        self._zero_col_var = tf.Variable(initial_value=zero_init(shape=(T + 1, 1), dtype='float32'), trainable=False)\n",
    "        self._zero_row_var = tf.Variable(initial_value=zero_init(shape=(1, T), dtype='float32'), trainable=False)\n",
    "\n",
    "        # mask:\n",
    "        t1 = tf.ones((T+1, T+1), dtype=\"float32\")\n",
    "        t2 = tf.subtract(t1, tf.eye(T+1, dtype=\"float32\"))\n",
    "        self._wout_mask = tf.multiply(tf.linalg.band_part(t1, 0, -1), t2)\n",
    "\n",
    "    def call(self, inputs, **kwargs):  # Defines the computation from inputs to outputs\n",
    "        # print(tf.shape(inputs)[0])\n",
    "        N = inputs.shape[0]\n",
    "        T = self.units\n",
    "        inp_lst = []\n",
    "\n",
    "        wout = tfp.math.fill_triangular(self._w, upper=True)\n",
    "        wout = tf.concat([wout, self._zero_row_var], axis=0)\n",
    "        wout = tf.concat([self._zero_col_var, wout], axis=1)\n",
    "\n",
    "        for t in range(N):\n",
    "            cur_input = tf.gather(inputs, t, axis=0)\n",
    "            cur_input = tf.tile(tf.reshape(cur_input, shape=(1, -1)), [T, 1])\n",
    "            logis = tf.multiply(cur_input, wout)\n",
    "\n",
    "            cur_mask = tf.multiply(cur_input, self._wout_mask)\n",
    "\n",
    "            inp_lst.append(tf.reshape(\n",
    "                tf.multiply(tf.transpose(tf.transpose(tf.exp(logis)) / tf.reduce_sum(tf.exp(logis), axis=1)),\n",
    "                              cur_mask), shape=(1, -1)))\n",
    "\n",
    "        res = tf.concat(inp_lst, axis=0)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "list_size = 10\n",
    "no_states = 11\n",
    "ubm_click_states = np.eye(list_size + 1, list_size + 1)\n",
    "abs_state = [(i, i) for i in range(no_states)]\n",
    "init_state = 0\n",
    "batch_size = 10000\n",
    "no_items = 100\n",
    "\n",
    "var_dic = {\n",
    "    'phi_A': {\n",
    "        'var_type': 'item',\n",
    "        'pos_mat': np.triu(np.ones((list_size + 1, list_size + 1)), k=1)\n",
    "    },\n",
    "    'gamma': {\n",
    "        'var_type': 'pos',\n",
    "        'pos_mat': np.triu(np.ones((list_size + 1, list_size + 1)), k=1)\n",
    "    }\n",
    "}\n",
    "\n",
    "model_def = ClickDefinition(ubm_click_states, init_state, list_size, no_states, batch_size, no_items, abs_state,\n",
    "                            var_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_count</th>\n",
       "      <th>item_order</th>\n",
       "      <th>click</th>\n",
       "      <th>attr</th>\n",
       "      <th>satis</th>\n",
       "      <th>eval</th>\n",
       "      <th>orig_list_id</th>\n",
       "      <th>index</th>\n",
       "      <th>session</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.617880</td>\n",
       "      <td>-0.424150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.463804</td>\n",
       "      <td>-0.667938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.849402</td>\n",
       "      <td>1.813430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.875517</td>\n",
       "      <td>-1.026840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.908807</td>\n",
       "      <td>0.050236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250565</th>\n",
       "      <td>85</td>\n",
       "      <td>17999</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35807</td>\n",
       "      <td>250560</td>\n",
       "      <td>25056</td>\n",
       "      <td>-0.362179</td>\n",
       "      <td>-0.737943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250566</th>\n",
       "      <td>3</td>\n",
       "      <td>17999</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35807</td>\n",
       "      <td>250560</td>\n",
       "      <td>25056</td>\n",
       "      <td>0.136692</td>\n",
       "      <td>0.039374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250567</th>\n",
       "      <td>76</td>\n",
       "      <td>17999</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35807</td>\n",
       "      <td>250560</td>\n",
       "      <td>25056</td>\n",
       "      <td>0.257214</td>\n",
       "      <td>-0.653226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250568</th>\n",
       "      <td>64</td>\n",
       "      <td>17999</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35807</td>\n",
       "      <td>250560</td>\n",
       "      <td>25056</td>\n",
       "      <td>-1.875517</td>\n",
       "      <td>-1.026840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250569</th>\n",
       "      <td>78</td>\n",
       "      <td>17999</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35807</td>\n",
       "      <td>250560</td>\n",
       "      <td>25056</td>\n",
       "      <td>-0.623121</td>\n",
       "      <td>-1.152936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250570 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item  user_id  session_count  item_order  click  attr  satis  eval  \\\n",
       "0         42        0              0           1    0.0     0      0   1.0   \n",
       "1         66        0              0           2    0.0     0      0   1.0   \n",
       "2         89        0              0           3    0.0     0      0   1.0   \n",
       "3         64        0              0           4    0.0     0      0   1.0   \n",
       "4         25        0              0           5    0.0     0      0   1.0   \n",
       "...      ...      ...            ...         ...    ...   ...    ...   ...   \n",
       "250565    85    17999              2           6    0.0     0      0   0.0   \n",
       "250566     3    17999              2           7    0.0     1      0   0.0   \n",
       "250567    76    17999              2           8    0.0     1      0   0.0   \n",
       "250568    64    17999              2           9    0.0     0      0   0.0   \n",
       "250569    78    17999              2          10    0.0     1      0   0.0   \n",
       "\n",
       "        orig_list_id   index  session        X0        X1  \n",
       "0                  0       0        0 -0.617880 -0.424150  \n",
       "1                  0       0        0 -0.463804 -0.667938  \n",
       "2                  0       0        0 -0.849402  1.813430  \n",
       "3                  0       0        0 -1.875517 -1.026840  \n",
       "4                  0       0        0 -0.908807  0.050236  \n",
       "...              ...     ...      ...       ...       ...  \n",
       "250565         35807  250560    25056 -0.362179 -0.737943  \n",
       "250566         35807  250560    25056  0.136692  0.039374  \n",
       "250567         35807  250560    25056  0.257214 -0.653226  \n",
       "250568         35807  250560    25056 -1.875517 -1.026840  \n",
       "250569         35807  250560    25056 -0.623121 -1.152936  \n",
       "\n",
       "[250570 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data:\n",
    "click_data = pd.read_csv(\"./data/small_example/simulation_res_train.csv\", index_col=False)\n",
    "prod_position = pd.read_csv(\"./data/small_example/simulation_item_props.csv\", index_col=False)\n",
    "\n",
    "# Ensure the order is correct:\n",
    "click_data = click_data.sort_values(['user_id', 'session_count', 'item_order'])\n",
    "\n",
    "# Add session index:\n",
    "session_index = (click_data\n",
    "                 .loc[:, ['user_id', 'session_count']]\n",
    "                 .drop_duplicates()\n",
    "                 .reset_index()\n",
    "                 )\n",
    "\n",
    "session_index['session'] = session_index.index.to_numpy()\n",
    "\n",
    "click_data = (click_data\n",
    "              .set_index(['user_id', 'session_count'])\n",
    "              .join(session_index\n",
    "                    .set_index(['user_id', 'session_count']),\n",
    "                    on=['user_id', 'session_count'])\n",
    "              .reset_index()\n",
    "              .set_index('item')\n",
    "              .join(prod_position\n",
    "                    .set_index('item'),\n",
    "                    on='item')\n",
    "              .reset_index()\n",
    "              )\n",
    "\n",
    "click_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the click matrix and item position matrix\n",
    "click_mat = click_data.loc[:, ['session', 'item_order', 'click']] \\\n",
    "    .pivot(index='session', columns='item_order', values='click') \\\n",
    "    .to_numpy()\n",
    "\n",
    "item_pos_mat = click_data.loc[:, ['session', 'item_order', 'item']] \\\n",
    "    .pivot(index='session', columns='item_order', values='item') \\\n",
    "    .to_numpy()\n",
    "\n",
    "# Ensure the order is correct\n",
    "item_feature_mat_A = (click_data.loc[:, ['item', 'X0', 'X1']]\n",
    "                                .drop_duplicates()\n",
    "                                .sort_values('item')\n",
    "                                .to_numpy())\n",
    "\n",
    "pos_feature_gamma = np.eye(model_def.list_size, model_def.list_size + 1, k=1)\n",
    "\n",
    "var_dic = {'phi_A': item_feature_mat_A, 'gamma': pos_feature_gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model:\n",
    "model_phi_A = Sequential()\n",
    "model_phi_A.add(Dense(1, input_dim=var_dic['phi_A'].shape[1], activation='sigmoid', use_bias=False))\n",
    "model_phi_A.compile(loss=GCM.pos_log_loss, optimizer=RMSprop())\n",
    "\n",
    "# Note the large output dimension and the softmax. We want multiple transition probabilities that sum up to 1\n",
    "# Its the shape**2, as we flatten the square matrix.\n",
    "model_gamma = Sequential()\n",
    "model_gamma.add(SimpleDense(no_states))\n",
    "model_gamma.compile(loss=GCM.pos_log_loss, optimizer=RMSprop())\n",
    "\n",
    "# model_tau = Sequential()\n",
    "# model_tau.add(Dense(var_dic['tau'].shape[1], input_dim=var_dic['tau'].shape[1], activation=None, use_bias=False,\n",
    "#                     kernel_initializer=Identity(), trainable=False))\n",
    "# model_tau.compile('rmsprop', 'binary_crossentropy')  # No trainable weights, so doesn't really matter\n",
    "\n",
    "var_models = {'phi_A': model_phi_A, 'gamma': model_gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Running E-step ...\n",
      "Current conditional entropy:0.57217\n",
      "Running M-step ...\n",
      "Epoch 1/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 53481.0039\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 522us/step - loss: 49215.1094\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 550us/step - loss: 46284.0312\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 748us/step - loss: 43935.1094\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 518us/step - loss: 41931.4336\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 752us/step - loss: 40163.4102\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - 0s 469us/step - loss: 38570.0469\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 714us/step - loss: 37113.3945\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 468us/step - loss: 35767.9844\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 650us/step - loss: 34515.7969\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 447us/step - loss: 33343.5039\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 418us/step - loss: 32240.9355\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 533us/step - loss: 31200.1133\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 830us/step - loss: 30214.6270\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 680us/step - loss: 29279.2305\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 582us/step - loss: 28389.5684\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 609us/step - loss: 27541.9316\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 522us/step - loss: 26733.1602\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 639us/step - loss: 25960.5098\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 562us/step - loss: 25221.5684\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 651us/step - loss: 24514.2109\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 535us/step - loss: 23836.5195\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 955us/step - loss: 23186.7930\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 555us/step - loss: 22563.4707\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 500us/step - loss: 21965.1250\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 704us/step - loss: 21390.4609\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 543us/step - loss: 20838.2773\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 676us/step - loss: 20307.4570\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 556us/step - loss: 19796.9688\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 998us/step - loss: 19305.8418\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 631us/step - loss: 18833.1699\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 531us/step - loss: 18378.1074\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - 0s 645us/step - loss: 17939.8516\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 533us/step - loss: 17517.6484\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 711us/step - loss: 17110.7852\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 612us/step - loss: 16718.5859\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 622us/step - loss: 16340.4150\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 591us/step - loss: 15975.6621\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 678us/step - loss: 15623.7500\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 600us/step - loss: 15284.1328\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 638us/step - loss: 14956.2891\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 654us/step - loss: 14639.7188\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 972us/step - loss: 14333.9521\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 585us/step - loss: 14038.5352\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 672us/step - loss: 13753.0391\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 530us/step - loss: 13477.0479\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 631us/step - loss: 13210.1729\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 567us/step - loss: 12952.0352\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 725us/step - loss: 12702.2842\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 828us/step - loss: 12460.5674\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 567us/step - loss: 12226.5654\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 11999.9609\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 550us/step - loss: 11780.4570\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 562us/step - loss: 11567.7695\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 555us/step - loss: 11361.6211\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 797us/step - loss: 11161.7529\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 744us/step - loss: 10967.9141\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 592us/step - loss: 10779.8672\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - 0s 865us/step - loss: 10597.3809\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 707us/step - loss: 10420.2412\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 603us/step - loss: 10248.2354\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 533us/step - loss: 10081.1650\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 678us/step - loss: 9918.8398\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 687us/step - loss: 9761.0762\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 645us/step - loss: 9607.6992\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 739us/step - loss: 9458.5430\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 569us/step - loss: 9313.4473\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 645us/step - loss: 9172.2598\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 592us/step - loss: 9034.8340\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 695us/step - loss: 8901.0293\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 615us/step - loss: 8770.7139\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 695us/step - loss: 8643.7578\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 604us/step - loss: 8520.0410\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 570us/step - loss: 8399.4434\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 754us/step - loss: 8281.8564\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 643us/step - loss: 8167.1714\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 8055.2852\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 7946.0996\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 698us/step - loss: 7839.5200\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 661us/step - loss: 7735.4580\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 7633.8267\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 534us/step - loss: 7534.5439\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 702us/step - loss: 7437.5293\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 804us/step - loss: 7342.7075\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 730us/step - loss: 7250.0059\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 568us/step - loss: 7159.3550\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7070.6880\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 850us/step - loss: 6983.9404\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 726us/step - loss: 6899.0508\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 839us/step - loss: 6815.9614\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 737us/step - loss: 6734.6133\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 770us/step - loss: 6654.9546\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 676us/step - loss: 6576.9316\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 693us/step - loss: 6500.4941\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 801us/step - loss: 6425.5952\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6352.1890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 694us/step - loss: 6280.2280\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 695us/step - loss: 6209.6719\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 548us/step - loss: 6140.4805\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 848us/step - loss: 6072.6123\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6006.0298\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 730us/step - loss: 5940.6973\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 654us/step - loss: 5876.5796\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5813.6411\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 529us/step - loss: 5751.8511\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 777us/step - loss: 5691.1777\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5631.5894\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 713us/step - loss: 5573.0586\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 625us/step - loss: 5515.5566\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 540us/step - loss: 5459.0566\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 838us/step - loss: 5403.5327\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 535us/step - loss: 5348.9575\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5295.3096\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5242.5645\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 799us/step - loss: 5190.6982\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 671us/step - loss: 5139.6909\n",
      "Epoch 117/250\n",
      "1/1 [==============================] - 0s 590us/step - loss: 5089.5200\n",
      "Epoch 118/250\n",
      "1/1 [==============================] - 0s 568us/step - loss: 5040.1660\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 586us/step - loss: 4991.6089\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 617us/step - loss: 4943.8291\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 690us/step - loss: 4896.8081\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 477us/step - loss: 4850.5293\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 707us/step - loss: 4804.9736\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 495us/step - loss: 4760.1260\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 604us/step - loss: 4715.9688\n",
      "Epoch 126/250\n",
      "1/1 [==============================] - 0s 586us/step - loss: 4672.4878\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 713us/step - loss: 4629.6670\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 742us/step - loss: 4587.4917\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 710us/step - loss: 4545.9487\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 495us/step - loss: 4505.0225\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 592us/step - loss: 4464.7012\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 521us/step - loss: 4424.9707\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 595us/step - loss: 4385.8193\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 858us/step - loss: 4347.2339\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 4309.2036\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 539us/step - loss: 4271.7168\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 507us/step - loss: 4234.7617\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 812us/step - loss: 4198.3281\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 557us/step - loss: 4162.4043\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 694us/step - loss: 4126.9814\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 520us/step - loss: 4092.0491\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 742us/step - loss: 4057.5974\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 541us/step - loss: 4023.6172\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 556us/step - loss: 3990.0994\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 516us/step - loss: 3957.0347\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 546us/step - loss: 3924.4141\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 555us/step - loss: 3892.2310\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 495us/step - loss: 3860.4751\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 641us/step - loss: 3829.1394\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 568us/step - loss: 3798.2156\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 590us/step - loss: 3767.6968\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 652us/step - loss: 3737.5752\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 801us/step - loss: 3707.8438\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 548us/step - loss: 3678.4951\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 518us/step - loss: 3649.5227\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 650us/step - loss: 3620.9199\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 681us/step - loss: 3592.6797\n",
      "Epoch 158/250\n",
      "1/1 [==============================] - 0s 612us/step - loss: 3564.7966\n",
      "Epoch 159/250\n",
      "1/1 [==============================] - 0s 505us/step - loss: 3537.2634\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 547us/step - loss: 3510.0745\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 494us/step - loss: 3483.2236\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 646us/step - loss: 3456.7065\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 475us/step - loss: 3430.5156\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 614us/step - loss: 3404.6465\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 521us/step - loss: 3379.0938\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 567us/step - loss: 3353.8518\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 542us/step - loss: 3328.9148\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 577us/step - loss: 3304.2783\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 485us/step - loss: 3279.9382\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 651us/step - loss: 3255.8882\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 611us/step - loss: 3232.1243\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 532us/step - loss: 3208.6426\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 576us/step - loss: 3185.4395\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 541us/step - loss: 3162.5078\n",
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 540us/step - loss: 3139.8447\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 476us/step - loss: 3117.4460\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 782us/step - loss: 3095.3066\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 581us/step - loss: 3073.4233\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 627us/step - loss: 3051.7932\n",
      "Epoch 180/250\n",
      "1/1 [==============================] - 0s 559us/step - loss: 3030.4099\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 809us/step - loss: 3009.2705\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 539us/step - loss: 2988.3713\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 671us/step - loss: 2967.7078\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 824us/step - loss: 2947.2778\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 576us/step - loss: 2927.0771\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 693us/step - loss: 2907.1028\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 523us/step - loss: 2887.3508\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 526us/step - loss: 2867.8196\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 569us/step - loss: 2848.5046\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 747us/step - loss: 2829.4026\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 679us/step - loss: 2810.5093\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 715us/step - loss: 2791.8232\n",
      "Epoch 193/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 995us/step - loss: 2773.3408\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 625us/step - loss: 2755.0588\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 2736.97 - 0s 1ms/step - loss: 2736.9751\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 819us/step - loss: 2719.0862\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 693us/step - loss: 2701.3906\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2683.8838\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 709us/step - loss: 2666.5637\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 652us/step - loss: 2649.4272\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2632.4724\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 569us/step - loss: 2615.6960\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2599.0967\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 742us/step - loss: 2582.6704\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 807us/step - loss: 2566.4155\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 715us/step - loss: 2550.3293\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 901us/step - loss: 2534.4111\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2518.6572\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 776us/step - loss: 2503.0654\n",
      "Epoch 210/250\n",
      "1/1 [==============================] - 0s 651us/step - loss: 2487.6333\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 834us/step - loss: 2472.3586\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 994us/step - loss: 2457.2395\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2442.2734\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2427.4585\n",
      "Epoch 215/250\n",
      "1/1 [==============================] - 0s 805us/step - loss: 2412.7932\n",
      "Epoch 216/250\n",
      "1/1 [==============================] - 0s 693us/step - loss: 2398.2749\n",
      "Epoch 217/250\n",
      "1/1 [==============================] - 0s 730us/step - loss: 2383.9019\n",
      "Epoch 218/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2369.6729\n",
      "Epoch 219/250\n",
      "1/1 [==============================] - 0s 753us/step - loss: 2355.5847\n",
      "Epoch 220/250\n",
      "1/1 [==============================] - 0s 665us/step - loss: 2341.6357\n",
      "Epoch 221/250\n",
      "1/1 [==============================] - 0s 804us/step - loss: 2327.8250\n",
      "Epoch 222/250\n",
      "1/1 [==============================] - 0s 791us/step - loss: 2314.1504\n",
      "Epoch 223/250\n",
      "1/1 [==============================] - 0s 645us/step - loss: 2300.6099\n",
      "Epoch 224/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2287.2012\n",
      "Epoch 225/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2273.9238\n",
      "Epoch 226/250\n",
      "1/1 [==============================] - 0s 992us/step - loss: 2260.7754\n",
      "Epoch 227/250\n",
      "1/1 [==============================] - 0s 694us/step - loss: 2247.7542\n",
      "Epoch 228/250\n",
      "1/1 [==============================] - 0s 735us/step - loss: 2234.8589\n",
      "Epoch 229/250\n",
      "1/1 [==============================] - 0s 764us/step - loss: 2222.0879\n",
      "Epoch 230/250\n",
      "1/1 [==============================] - 0s 730us/step - loss: 2209.4392\n",
      "Epoch 231/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2196.9116\n",
      "Epoch 232/250\n",
      "1/1 [==============================] - 0s 811us/step - loss: 2184.5029\n",
      "Epoch 233/250\n",
      "1/1 [==============================] - 0s 804us/step - loss: 2172.2119\n",
      "Epoch 234/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2160.0374\n",
      "Epoch 235/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2147.9771\n",
      "Epoch 236/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2136.0300\n",
      "Epoch 237/250\n",
      "1/1 [==============================] - 0s 606us/step - loss: 2124.1953\n",
      "Epoch 238/250\n",
      "1/1 [==============================] - 0s 725us/step - loss: 2112.4707\n",
      "Epoch 239/250\n",
      "1/1 [==============================] - 0s 963us/step - loss: 2100.8547\n",
      "Epoch 240/250\n",
      "1/1 [==============================] - 0s 585us/step - loss: 2089.3464\n",
      "Epoch 241/250\n",
      "1/1 [==============================] - 0s 586us/step - loss: 2077.9443\n",
      "Epoch 242/250\n",
      "1/1 [==============================] - 0s 723us/step - loss: 2066.6470\n",
      "Epoch 243/250\n",
      "1/1 [==============================] - 0s 598us/step - loss: 2055.4531\n",
      "Epoch 244/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2044.3612\n",
      "Epoch 245/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2033.3715\n",
      "Epoch 246/250\n",
      "1/1 [==============================] - 0s 943us/step - loss: 2022.4808\n",
      "Epoch 247/250\n",
      "1/1 [==============================] - 0s 751us/step - loss: 2011.6885\n",
      "Epoch 248/250\n",
      "1/1 [==============================] - 0s 696us/step - loss: 2000.9938\n",
      "Epoch 249/250\n",
      "1/1 [==============================] - 0s 685us/step - loss: 1990.3955\n",
      "Epoch 250/250\n",
      "1/1 [==============================] - 0s 808us/step - loss: 1979.8921\n",
      "Epoch 1/250\n",
      "WARNING:tensorflow:Model was constructed with shape (10, 11) for input Tensor(\"simple_dense_input:0\", shape=(10, 11), dtype=float32), but it was called on an input with incompatible shape (20, 11).\n",
      "WARNING:tensorflow:Model was constructed with shape (10, 11) for input Tensor(\"simple_dense_input:0\", shape=(10, 11), dtype=float32), but it was called on an input with incompatible shape (20, 11).\n",
      "1/1 [==============================] - 0s 860us/step - loss: 48276776.0000\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 565us/step - loss: 48276540.0000\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 620us/step - loss: 48276344.0000\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 492us/step - loss: 48276192.0000\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 531us/step - loss: 48276072.0000\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 464us/step - loss: 48275952.0000\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - 0s 542us/step - loss: 48275808.0000\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 464us/step - loss: 48275668.0000\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 516us/step - loss: 48275604.0000\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 853us/step - loss: 48275520.0000\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 478us/step - loss: 48275388.0000\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 626us/step - loss: 48275280.0000\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 552us/step - loss: 48275208.0000\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 537us/step - loss: 48275084.0000\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 589us/step - loss: 48275052.0000\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 507us/step - loss: 48274928.0000\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 568us/step - loss: 48274824.0000\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 681us/step - loss: 48274752.0000\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 699us/step - loss: 48274680.0000\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 512us/step - loss: 48274592.0000\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 578us/step - loss: 48274472.0000\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 575us/step - loss: 48274400.0000\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 496us/step - loss: 48274332.0000\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 603us/step - loss: 48274256.0000\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 610us/step - loss: 48274160.0000\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 601us/step - loss: 48274076.0000\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 489us/step - loss: 48273976.0000\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 665us/step - loss: 48273916.0000\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 591us/step - loss: 48273816.0000\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 671us/step - loss: 48273756.0000\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 652us/step - loss: 48273656.0000\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 616us/step - loss: 48273572.0000\n",
      "Epoch 33/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 531us/step - loss: 48273488.0000\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 612us/step - loss: 48273384.0000\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 506us/step - loss: 48273340.0000\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 605us/step - loss: 48273248.0000\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 709us/step - loss: 48273176.0000\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 625us/step - loss: 48273080.0000\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 618us/step - loss: 48273000.0000\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 598us/step - loss: 48272960.0000\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 618us/step - loss: 48272840.0000\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 48272768.0000\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 627us/step - loss: 48272712.0000\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 773us/step - loss: 48272592.0000\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 678us/step - loss: 48272536.0000\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 649us/step - loss: 48272432.0000\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 621us/step - loss: 48272364.0000\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 622us/step - loss: 48272276.0000\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 726us/step - loss: 48272196.0000\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 633us/step - loss: 48272140.0000\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 643us/step - loss: 48272028.0000\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 630us/step - loss: 48271944.0000\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 646us/step - loss: 48271860.0000\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 752us/step - loss: 48271816.0000\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 693us/step - loss: 48271736.0000\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 686us/step - loss: 48271652.0000\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 710us/step - loss: 48271552.0000\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 658us/step - loss: 48271488.0000\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - 0s 740us/step - loss: 48271372.0000\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 658us/step - loss: 48271308.0000\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 630us/step - loss: 48271260.0000\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - 0s 667us/step - loss: 48271172.0000\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 48271072.0000\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 598us/step - loss: 48271012.0000\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 700us/step - loss: 48270892.0000\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 48270840.0000\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 652us/step - loss: 48270756.0000\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 659us/step - loss: 48270688.0000\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 698us/step - loss: 48270616.0000\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 620us/step - loss: 48270500.0000\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 579us/step - loss: 48270412.0000\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 599us/step - loss: 48270336.0000\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 656us/step - loss: 48270284.0000\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 633us/step - loss: 48270224.0000\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 708us/step - loss: 48270124.0000\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 614us/step - loss: 48270052.0000\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 771us/step - loss: 48269992.0000\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 629us/step - loss: 48269880.0000\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 870us/step - loss: 48269788.0000\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 739us/step - loss: 48269720.0000\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 674us/step - loss: 48269672.0000\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 905us/step - loss: 48269556.0000\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 842us/step - loss: 48269492.0000\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48269416.0000\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 731us/step - loss: 48269344.0000\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 756us/step - loss: 48269232.0000\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48269152.0000\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48269072.0000\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 802us/step - loss: 48269020.0000\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 835us/step - loss: 48268920.0000\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48268844.0000\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 707us/step - loss: 48268752.0000\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 827us/step - loss: 48268672.0000\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48268596.0000\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 834us/step - loss: 48268524.0000\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 48268472.0000\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 634us/step - loss: 48268360.0000\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 727us/step - loss: 48268312.0000\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48268200.0000\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 670us/step - loss: 48268104.0000\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - 0s 657us/step - loss: 48268048.0000\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 797us/step - loss: 48267960.0000\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 737us/step - loss: 48267888.0000\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 725us/step - loss: 48267808.0000\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 573us/step - loss: 48267760.0000\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 795us/step - loss: 48267652.0000\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 746us/step - loss: 48267576.0000\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 48267504.0000\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 827us/step - loss: 48267416.0000\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48267320.0000\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 640us/step - loss: 48267236.0000\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 690us/step - loss: 48267172.0000\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 687us/step - loss: 48267076.0000\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48267032.0000\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 723us/step - loss: 48266920.0000\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 717us/step - loss: 48266856.0000\n",
      "Epoch 117/250\n",
      "1/1 [==============================] - 0s 722us/step - loss: 48266756.0000\n",
      "Epoch 118/250\n",
      "1/1 [==============================] - 0s 675us/step - loss: 48266720.0000\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 611us/step - loss: 48266632.0000\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 660us/step - loss: 48266536.0000\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 783us/step - loss: 48266452.0000\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 828us/step - loss: 48266392.0000\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 882us/step - loss: 48266304.0000\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48266208.0000\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 843us/step - loss: 48266112.0000\n",
      "Epoch 126/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 48266088.0000\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48265972.0000\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 48265900.0000\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 908us/step - loss: 48265816.0000\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48265776.0000\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48265656.0000\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 719us/step - loss: 48265604.0000\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 694us/step - loss: 48265496.0000\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 48265412.0000\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 938us/step - loss: 48265344.0000\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48265236.0000\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 721us/step - loss: 48265160.0000\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 758us/step - loss: 48265128.0000\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 743us/step - loss: 48265016.0000\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 712us/step - loss: 48264956.0000\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48264904.0000\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 638us/step - loss: 48264792.0000\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 945us/step - loss: 48264712.0000\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 782us/step - loss: 48264632.0000\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 773us/step - loss: 48264580.0000\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 899us/step - loss: 48264460.0000\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 872us/step - loss: 48264408.0000\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 779us/step - loss: 48264300.0000\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48264256.0000\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48264164.0000\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 657us/step - loss: 48264060.0000\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 623us/step - loss: 48263968.0000\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 628us/step - loss: 48263912.0000\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 768us/step - loss: 48263832.0000\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 872us/step - loss: 48263760.0000\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 881us/step - loss: 48263672.0000\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 911us/step - loss: 48263624.0000\n",
      "Epoch 158/250\n",
      "1/1 [==============================] - 0s 783us/step - loss: 48263528.0000\n",
      "Epoch 159/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48263468.0000\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 719us/step - loss: 48263372.0000\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 655us/step - loss: 48263284.0000\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 622us/step - loss: 48263200.0000\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 597us/step - loss: 48263136.0000\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 650us/step - loss: 48263052.0000\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 735us/step - loss: 48262984.0000\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 831us/step - loss: 48262888.0000\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 747us/step - loss: 48262820.0000\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48262736.0000\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48262636.0000\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48262576.0000\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 651us/step - loss: 48262488.0000\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 801us/step - loss: 48262436.0000\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 711us/step - loss: 48262312.0000\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 750us/step - loss: 48262272.0000\n",
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 823us/step - loss: 48262184.0000\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 690us/step - loss: 48262076.0000\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 678us/step - loss: 48262012.0000\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 905us/step - loss: 48261932.0000\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48261888.0000\n",
      "Epoch 180/250\n",
      "1/1 [==============================] - 0s 737us/step - loss: 48261784.0000\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48261720.0000\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 867us/step - loss: 48261624.0000\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 705us/step - loss: 48261548.0000\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 633us/step - loss: 48261460.0000\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 801us/step - loss: 48261388.0000\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 747us/step - loss: 48261344.0000\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48261212.0000\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 814us/step - loss: 48261152.0000\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 684us/step - loss: 48261044.0000\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 653us/step - loss: 48260996.0000\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48260900.0000\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 777us/step - loss: 48260856.0000\n",
      "Epoch 193/250\n",
      "1/1 [==============================] - 0s 707us/step - loss: 48260756.0000\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48260640.0000\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48260644.0000\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 721us/step - loss: 48260504.0000\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48260432.0000\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 48260348.0000\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 717us/step - loss: 48260292.0000\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 845us/step - loss: 48260176.0000\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 611us/step - loss: 48260124.0000\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 637us/step - loss: 48260028.0000\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 597us/step - loss: 48259968.0000\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 659us/step - loss: 48259876.0000\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 672us/step - loss: 48259808.0000\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 685us/step - loss: 48259716.0000\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 990us/step - loss: 48259640.0000\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 695us/step - loss: 48259564.0000\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 665us/step - loss: 48259508.0000\n",
      "Epoch 210/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48259424.0000\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48259340.0000\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 648us/step - loss: 48259252.0000\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 601us/step - loss: 48259172.0000\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - 0s 721us/step - loss: 48259092.0000\n",
      "Epoch 215/250\n",
      "1/1 [==============================] - 0s 660us/step - loss: 48259012.0000\n",
      "Epoch 216/250\n",
      "1/1 [==============================] - 0s 780us/step - loss: 48258944.0000\n",
      "Epoch 217/250\n",
      "1/1 [==============================] - 0s 693us/step - loss: 48258860.0000\n",
      "Epoch 218/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 733us/step - loss: 48258768.0000\n",
      "Epoch 219/250\n",
      "1/1 [==============================] - 0s 629us/step - loss: 48258700.0000\n",
      "Epoch 220/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48258624.0000\n",
      "Epoch 221/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48258532.0000\n",
      "Epoch 222/250\n",
      "1/1 [==============================] - 0s 660us/step - loss: 48258452.0000\n",
      "Epoch 223/250\n",
      "1/1 [==============================] - 0s 627us/step - loss: 48258392.0000\n",
      "Epoch 224/250\n",
      "1/1 [==============================] - 0s 831us/step - loss: 48258304.0000\n",
      "Epoch 225/250\n",
      "1/1 [==============================] - 0s 737us/step - loss: 48258256.0000\n",
      "Epoch 226/250\n",
      "1/1 [==============================] - 0s 970us/step - loss: 48258160.0000\n",
      "Epoch 227/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48258088.0000\n",
      "Epoch 228/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 48257980.0000\n",
      "Epoch 229/250\n",
      "1/1 [==============================] - 0s 600us/step - loss: 48257892.0000\n",
      "Epoch 230/250\n",
      "1/1 [==============================] - 0s 739us/step - loss: 48257816.0000\n",
      "Epoch 231/250\n",
      "1/1 [==============================] - 0s 710us/step - loss: 48257768.0000\n",
      "Epoch 232/250\n",
      "1/1 [==============================] - 0s 701us/step - loss: 48257668.0000\n",
      "Epoch 233/250\n",
      "1/1 [==============================] - 0s 706us/step - loss: 48257620.0000\n",
      "Epoch 234/250\n",
      "1/1 [==============================] - 0s 742us/step - loss: 48257552.0000\n",
      "Epoch 235/250\n",
      "1/1 [==============================] - 0s 983us/step - loss: 48257440.0000\n",
      "Epoch 236/250\n",
      "1/1 [==============================] - 0s 682us/step - loss: 48257352.0000\n",
      "Epoch 237/250\n",
      "1/1 [==============================] - 0s 715us/step - loss: 48257260.0000\n",
      "Epoch 238/250\n",
      "1/1 [==============================] - 0s 808us/step - loss: 48257196.0000\n",
      "Epoch 239/250\n",
      "1/1 [==============================] - 0s 756us/step - loss: 48257124.0000\n",
      "Epoch 240/250\n",
      "1/1 [==============================] - 0s 621us/step - loss: 48257040.0000\n",
      "Epoch 241/250\n",
      "1/1 [==============================] - 0s 727us/step - loss: 48257008.0000\n",
      "Epoch 242/250\n",
      "1/1 [==============================] - 0s 676us/step - loss: 48256888.0000\n",
      "Epoch 243/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48256840.0000\n",
      "Epoch 244/250\n",
      "1/1 [==============================] - 0s 779us/step - loss: 48256728.0000\n",
      "Epoch 245/250\n",
      "1/1 [==============================] - 0s 681us/step - loss: 48256672.0000\n",
      "Epoch 246/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 48256560.0000\n",
      "Epoch 247/250\n",
      "1/1 [==============================] - 0s 595us/step - loss: 48256492.0000\n",
      "Epoch 248/250\n",
      "1/1 [==============================] - 0s 667us/step - loss: 48256448.0000\n",
      "Epoch 249/250\n",
      "1/1 [==============================] - 0s 607us/step - loss: 48256344.0000\n",
      "Epoch 250/250\n",
      "1/1 [==============================] - 0s 651us/step - loss: 48256256.0000\n",
      "Iteration: 1\n",
      "Current norm: 7.30177\n",
      "Running E-step ...\n",
      "Current conditional entropy:0.41228\n",
      "Running M-step ...\n",
      "Epoch 1/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1969.4827\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - 0s 515us/step - loss: 1959.1659\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - 0s 533us/step - loss: 1948.9407\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - 0s 522us/step - loss: 1938.8062\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - 0s 438us/step - loss: 1928.7610\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - 0s 552us/step - loss: 1918.8041\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - 0s 785us/step - loss: 1908.9347\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - 0s 488us/step - loss: 1899.1516\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - 0s 625us/step - loss: 1889.4541\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - 0s 448us/step - loss: 1879.8402\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - 0s 650us/step - loss: 1870.3097\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - 0s 480us/step - loss: 1860.8617\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - 0s 524us/step - loss: 1851.4946\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - 0s 465us/step - loss: 1842.2078\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - 0s 598us/step - loss: 1833.0004\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - 0s 630us/step - loss: 1823.8707\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - 0s 584us/step - loss: 1814.8196\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - 0s 517us/step - loss: 1805.8450\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - 0s 518us/step - loss: 1796.9459\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - 0s 596us/step - loss: 1788.1217\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - 0s 527us/step - loss: 1779.3717\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - 0s 597us/step - loss: 1770.6948\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - 0s 540us/step - loss: 1762.0906\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - 0s 626us/step - loss: 1753.5582\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - 0s 559us/step - loss: 1745.0962\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - 0s 603us/step - loss: 1736.7039\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - 0s 514us/step - loss: 1728.3805\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - 0s 574us/step - loss: 1720.1255\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - 0s 484us/step - loss: 1711.9380\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - 0s 640us/step - loss: 1703.8168\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - 0s 591us/step - loss: 1695.7621\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - 0s 645us/step - loss: 1687.7725\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - 0s 563us/step - loss: 1679.8477\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - 0s 604us/step - loss: 1671.9862\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - 0s 497us/step - loss: 1664.1882\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - 0s 603us/step - loss: 1656.4528\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - 0s 473us/step - loss: 1648.7798\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - 0s 589us/step - loss: 1641.1675\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - 0s 509us/step - loss: 1633.6154\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - 0s 644us/step - loss: 1626.1233\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - 0s 565us/step - loss: 1618.6899\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - 0s 592us/step - loss: 1611.3148\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - 0s 480us/step - loss: 1603.9978\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - 0s 572us/step - loss: 1596.7378\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - 0s 488us/step - loss: 1589.5342\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - 0s 586us/step - loss: 1582.3864\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - 0s 505us/step - loss: 1575.2944\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - 0s 763us/step - loss: 1568.2567\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - 0s 561us/step - loss: 1561.2734\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - 0s 591us/step - loss: 1554.3441\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - 0s 486us/step - loss: 1547.4673\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - 0s 583us/step - loss: 1540.6431\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - 0s 493us/step - loss: 1533.8707\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - 0s 611us/step - loss: 1527.1500\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - 0s 565us/step - loss: 1520.4801\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - 0s 616us/step - loss: 1513.8606\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - 0s 540us/step - loss: 1507.2911\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - 0s 577us/step - loss: 1500.7703\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - 0s 466us/step - loss: 1494.2990\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - 0s 596us/step - loss: 1487.8751\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - 0s 491us/step - loss: 1481.4993\n",
      "Epoch 62/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 588us/step - loss: 1475.1707\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - 0s 472us/step - loss: 1468.8892\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - 0s 609us/step - loss: 1462.6538\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - 0s 518us/step - loss: 1456.4645\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - 0s 588us/step - loss: 1450.3204\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - 0s 514us/step - loss: 1444.2214\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - 0s 594us/step - loss: 1438.1667\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - 0s 508us/step - loss: 1432.1562\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - 0s 625us/step - loss: 1426.1893\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - 0s 564us/step - loss: 1420.2660\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - 0s 638us/step - loss: 1414.3857\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - 0s 549us/step - loss: 1408.5472\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - 0s 617us/step - loss: 1402.7507\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - 0s 511us/step - loss: 1396.9956\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - 0s 630us/step - loss: 1391.2816\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - 0s 563us/step - loss: 1385.6077\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - 0s 723us/step - loss: 1379.9744\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - 0s 532us/step - loss: 1374.3806\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - 0s 654us/step - loss: 1368.8267\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - 0s 582us/step - loss: 1363.3114\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - 0s 624us/step - loss: 1357.8352\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - 0s 520us/step - loss: 1352.3969\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - 0s 683us/step - loss: 1346.9967\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - 0s 500us/step - loss: 1341.6340\n",
      "Epoch 86/250\n",
      "1/1 [==============================] - 0s 542us/step - loss: 1336.3086\n",
      "Epoch 87/250\n",
      "1/1 [==============================] - 0s 610us/step - loss: 1331.0205\n",
      "Epoch 88/250\n",
      "1/1 [==============================] - 0s 539us/step - loss: 1325.7690\n",
      "Epoch 89/250\n",
      "1/1 [==============================] - 0s 605us/step - loss: 1320.5532\n",
      "Epoch 90/250\n",
      "1/1 [==============================] - 0s 519us/step - loss: 1315.3734\n",
      "Epoch 91/250\n",
      "1/1 [==============================] - 0s 609us/step - loss: 1310.2291\n",
      "Epoch 92/250\n",
      "1/1 [==============================] - 0s 495us/step - loss: 1305.1199\n",
      "Epoch 93/250\n",
      "1/1 [==============================] - 0s 780us/step - loss: 1300.0459\n",
      "Epoch 94/250\n",
      "1/1 [==============================] - 0s 526us/step - loss: 1295.0062\n",
      "Epoch 95/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1290.0009\n",
      "Epoch 96/250\n",
      "1/1 [==============================] - 0s 743us/step - loss: 1285.0292\n",
      "Epoch 97/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1280.0913\n",
      "Epoch 98/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1275.1864\n",
      "Epoch 99/250\n",
      "1/1 [==============================] - 0s 619us/step - loss: 1270.3145\n",
      "Epoch 100/250\n",
      "1/1 [==============================] - 0s 668us/step - loss: 1265.4750\n",
      "Epoch 101/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1260.66 - 0s 1ms/step - loss: 1260.6680\n",
      "Epoch 102/250\n",
      "1/1 [==============================] - 0s 732us/step - loss: 1255.8933\n",
      "Epoch 103/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1251.1499\n",
      "Epoch 104/250\n",
      "1/1 [==============================] - 0s 720us/step - loss: 1246.4380\n",
      "Epoch 105/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1241.7572\n",
      "Epoch 106/250\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1237.1074\n",
      "Epoch 107/250\n",
      "1/1 [==============================] - 0s 688us/step - loss: 1232.4878\n",
      "Epoch 108/250\n",
      "1/1 [==============================] - 0s 520us/step - loss: 1227.8984\n",
      "Epoch 109/250\n",
      "1/1 [==============================] - 0s 723us/step - loss: 1223.3392\n",
      "Epoch 110/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1218.8096\n",
      "Epoch 111/250\n",
      "1/1 [==============================] - 0s 765us/step - loss: 1214.3096\n",
      "Epoch 112/250\n",
      "1/1 [==============================] - 0s 748us/step - loss: 1209.8387\n",
      "Epoch 113/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1205.3969\n",
      "Epoch 114/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1200.9836\n",
      "Epoch 115/250\n",
      "1/1 [==============================] - 0s 541us/step - loss: 1196.5990\n",
      "Epoch 116/250\n",
      "1/1 [==============================] - 0s 570us/step - loss: 1192.2424\n",
      "Epoch 117/250\n",
      "1/1 [==============================] - 0s 879us/step - loss: 1187.9135\n",
      "Epoch 118/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 1183.6125\n",
      "Epoch 119/250\n",
      "1/1 [==============================] - 0s 695us/step - loss: 1179.3389\n",
      "Epoch 120/250\n",
      "1/1 [==============================] - 0s 770us/step - loss: 1175.0925\n",
      "Epoch 121/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1170.8728\n",
      "Epoch 122/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1166.6799\n",
      "Epoch 123/250\n",
      "1/1 [==============================] - 0s 695us/step - loss: 1162.5137\n",
      "Epoch 124/250\n",
      "1/1 [==============================] - 0s 986us/step - loss: 1158.3738\n",
      "Epoch 125/250\n",
      "1/1 [==============================] - 0s 759us/step - loss: 1154.2598\n",
      "Epoch 126/250\n",
      "1/1 [==============================] - 0s 720us/step - loss: 1150.1716\n",
      "Epoch 127/250\n",
      "1/1 [==============================] - 0s 702us/step - loss: 1146.1089\n",
      "Epoch 128/250\n",
      "1/1 [==============================] - 0s 719us/step - loss: 1142.0715\n",
      "Epoch 129/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 1138.0592\n",
      "Epoch 130/250\n",
      "1/1 [==============================] - 0s 945us/step - loss: 1134.0721\n",
      "Epoch 131/250\n",
      "1/1 [==============================] - 0s 469us/step - loss: 1130.1093\n",
      "Epoch 132/250\n",
      "1/1 [==============================] - 0s 676us/step - loss: 1126.1710\n",
      "Epoch 133/250\n",
      "1/1 [==============================] - 0s 475us/step - loss: 1122.2573\n",
      "Epoch 134/250\n",
      "1/1 [==============================] - 0s 648us/step - loss: 1118.3673\n",
      "Epoch 135/250\n",
      "1/1 [==============================] - 0s 554us/step - loss: 1114.5010\n",
      "Epoch 136/250\n",
      "1/1 [==============================] - 0s 599us/step - loss: 1110.6588\n",
      "Epoch 137/250\n",
      "1/1 [==============================] - 0s 478us/step - loss: 1106.8398\n",
      "Epoch 138/250\n",
      "1/1 [==============================] - 0s 657us/step - loss: 1103.0443\n",
      "Epoch 139/250\n",
      "1/1 [==============================] - 0s 476us/step - loss: 1099.2719\n",
      "Epoch 140/250\n",
      "1/1 [==============================] - 0s 543us/step - loss: 1095.5222\n",
      "Epoch 141/250\n",
      "1/1 [==============================] - 0s 518us/step - loss: 1091.7955\n",
      "Epoch 142/250\n",
      "1/1 [==============================] - 0s 595us/step - loss: 1088.0916\n",
      "Epoch 143/250\n",
      "1/1 [==============================] - 0s 584us/step - loss: 1084.4099\n",
      "Epoch 144/250\n",
      "1/1 [==============================] - 0s 847us/step - loss: 1080.7496\n",
      "Epoch 145/250\n",
      "1/1 [==============================] - 0s 568us/step - loss: 1077.1118\n",
      "Epoch 146/250\n",
      "1/1 [==============================] - 0s 639us/step - loss: 1073.4956\n",
      "Epoch 147/250\n",
      "1/1 [==============================] - 0s 689us/step - loss: 1069.9009\n",
      "Epoch 148/250\n",
      "1/1 [==============================] - 0s 607us/step - loss: 1066.3276\n",
      "Epoch 149/250\n",
      "1/1 [==============================] - 0s 930us/step - loss: 1062.7756\n",
      "Epoch 150/250\n",
      "1/1 [==============================] - 0s 643us/step - loss: 1059.2445\n",
      "Epoch 151/250\n",
      "1/1 [==============================] - 0s 708us/step - loss: 1055.7346\n",
      "Epoch 152/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1052.2451\n",
      "Epoch 153/250\n",
      "1/1 [==============================] - 0s 655us/step - loss: 1048.7761\n",
      "Epoch 154/250\n",
      "1/1 [==============================] - 0s 669us/step - loss: 1045.3275\n",
      "Epoch 155/250\n",
      "1/1 [==============================] - 0s 782us/step - loss: 1041.8990\n",
      "Epoch 156/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1038.4904\n",
      "Epoch 157/250\n",
      "1/1 [==============================] - 0s 849us/step - loss: 1035.1016\n",
      "Epoch 158/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1031.7329\n",
      "Epoch 159/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 1028.3834\n",
      "Epoch 160/250\n",
      "1/1 [==============================] - 0s 489us/step - loss: 1025.0532\n",
      "Epoch 161/250\n",
      "1/1 [==============================] - 0s 639us/step - loss: 1021.7422\n",
      "Epoch 162/250\n",
      "1/1 [==============================] - 0s 488us/step - loss: 1018.4504\n",
      "Epoch 163/250\n",
      "1/1 [==============================] - 0s 585us/step - loss: 1015.1775\n",
      "Epoch 164/250\n",
      "1/1 [==============================] - 0s 488us/step - loss: 1011.9231\n",
      "Epoch 165/250\n",
      "1/1 [==============================] - 0s 564us/step - loss: 1008.6873\n",
      "Epoch 166/250\n",
      "1/1 [==============================] - 0s 494us/step - loss: 1005.4703\n",
      "Epoch 167/250\n",
      "1/1 [==============================] - 0s 605us/step - loss: 1002.2713\n",
      "Epoch 168/250\n",
      "1/1 [==============================] - 0s 511us/step - loss: 999.0908\n",
      "Epoch 169/250\n",
      "1/1 [==============================] - 0s 621us/step - loss: 995.9280\n",
      "Epoch 170/250\n",
      "1/1 [==============================] - 0s 680us/step - loss: 992.7834\n",
      "Epoch 171/250\n",
      "1/1 [==============================] - 0s 637us/step - loss: 989.6561\n",
      "Epoch 172/250\n",
      "1/1 [==============================] - 0s 510us/step - loss: 986.5467\n",
      "Epoch 173/250\n",
      "1/1 [==============================] - 0s 726us/step - loss: 983.4549\n",
      "Epoch 174/250\n",
      "1/1 [==============================] - 0s 613us/step - loss: 980.3807\n",
      "Epoch 175/250\n",
      "1/1 [==============================] - 0s 703us/step - loss: 977.3234\n",
      "Epoch 176/250\n",
      "1/1 [==============================] - 0s 545us/step - loss: 974.2830\n",
      "Epoch 177/250\n",
      "1/1 [==============================] - 0s 821us/step - loss: 971.2597\n",
      "Epoch 178/250\n",
      "1/1 [==============================] - 0s 652us/step - loss: 968.2531\n",
      "Epoch 179/250\n",
      "1/1 [==============================] - 0s 823us/step - loss: 965.2631\n",
      "Epoch 180/250\n",
      "1/1 [==============================] - 0s 542us/step - loss: 962.2896\n",
      "Epoch 181/250\n",
      "1/1 [==============================] - 0s 737us/step - loss: 959.3325\n",
      "Epoch 182/250\n",
      "1/1 [==============================] - 0s 994us/step - loss: 956.3915\n",
      "Epoch 183/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 953.4667\n",
      "Epoch 184/250\n",
      "1/1 [==============================] - 0s 771us/step - loss: 950.5580\n",
      "Epoch 185/250\n",
      "1/1 [==============================] - 0s 699us/step - loss: 947.6650\n",
      "Epoch 186/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 944.7881\n",
      "Epoch 187/250\n",
      "1/1 [==============================] - 0s 998us/step - loss: 941.9265\n",
      "Epoch 188/250\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 939.0806\n",
      "Epoch 189/250\n",
      "1/1 [==============================] - 0s 701us/step - loss: 936.2498\n",
      "Epoch 190/250\n",
      "1/1 [==============================] - 0s 919us/step - loss: 933.4344\n",
      "Epoch 191/250\n",
      "1/1 [==============================] - 0s 788us/step - loss: 930.6346\n",
      "Epoch 192/250\n",
      "1/1 [==============================] - 0s 697us/step - loss: 927.8498\n",
      "Epoch 193/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 925.0797\n",
      "Epoch 194/250\n",
      "1/1 [==============================] - 0s 831us/step - loss: 922.3247\n",
      "Epoch 195/250\n",
      "1/1 [==============================] - 0s 537us/step - loss: 919.5842\n",
      "Epoch 196/250\n",
      "1/1 [==============================] - 0s 814us/step - loss: 916.8585\n",
      "Epoch 197/250\n",
      "1/1 [==============================] - 0s 528us/step - loss: 914.1469\n",
      "Epoch 198/250\n",
      "1/1 [==============================] - 0s 746us/step - loss: 911.4501\n",
      "Epoch 199/250\n",
      "1/1 [==============================] - 0s 757us/step - loss: 908.7674\n",
      "Epoch 200/250\n",
      "1/1 [==============================] - 0s 526us/step - loss: 906.0986\n",
      "Epoch 201/250\n",
      "1/1 [==============================] - 0s 760us/step - loss: 903.4441\n",
      "Epoch 202/250\n",
      "1/1 [==============================] - 0s 589us/step - loss: 900.8035\n",
      "Epoch 203/250\n",
      "1/1 [==============================] - 0s 753us/step - loss: 898.1770\n",
      "Epoch 204/250\n",
      "1/1 [==============================] - 0s 577us/step - loss: 895.5643\n",
      "Epoch 205/250\n",
      "1/1 [==============================] - 0s 561us/step - loss: 892.9655\n",
      "Epoch 206/250\n",
      "1/1 [==============================] - 0s 579us/step - loss: 890.3798\n",
      "Epoch 207/250\n",
      "1/1 [==============================] - 0s 543us/step - loss: 887.8077\n",
      "Epoch 208/250\n",
      "1/1 [==============================] - 0s 646us/step - loss: 885.2491\n",
      "Epoch 209/250\n",
      "1/1 [==============================] - 0s 714us/step - loss: 882.7037\n",
      "Epoch 210/250\n",
      "1/1 [==============================] - 0s 663us/step - loss: 880.1711\n",
      "Epoch 211/250\n",
      "1/1 [==============================] - 0s 630us/step - loss: 877.6517\n",
      "Epoch 212/250\n",
      "1/1 [==============================] - 0s 545us/step - loss: 875.1453\n",
      "Epoch 213/250\n",
      "1/1 [==============================] - 0s 763us/step - loss: 872.6517\n",
      "Epoch 214/250\n",
      "1/1 [==============================] - 0s 478us/step - loss: 870.1711\n",
      "Epoch 215/250\n",
      "1/1 [==============================] - 0s 644us/step - loss: 867.7028\n",
      "Epoch 216/250\n",
      "1/1 [==============================] - 0s 579us/step - loss: 865.2475\n",
      "Epoch 217/250\n",
      "1/1 [==============================] - 0s 763us/step - loss: 862.8043\n",
      "Epoch 218/250\n",
      "1/1 [==============================] - 0s 549us/step - loss: 860.3738\n",
      "Epoch 219/250\n",
      "1/1 [==============================] - 0s 534us/step - loss: 857.9556\n",
      "Epoch 220/250\n",
      "1/1 [==============================] - 0s 559us/step - loss: 855.5492\n",
      "Epoch 221/250\n",
      "1/1 [==============================] - 0s 522us/step - loss: 853.1553\n",
      "Epoch 222/250\n",
      "1/1 [==============================] - 0s 586us/step - loss: 850.7733\n",
      "Epoch 223/250\n",
      "1/1 [==============================] - 0s 545us/step - loss: 848.4032\n",
      "Epoch 224/250\n",
      "1/1 [==============================] - 0s 751us/step - loss: 846.0449\n",
      "Epoch 225/250\n",
      "1/1 [==============================] - 0s 484us/step - loss: 843.6986\n",
      "Epoch 226/250\n",
      "1/1 [==============================] - 0s 557us/step - loss: 841.3638\n",
      "Epoch 227/250\n",
      "1/1 [==============================] - 0s 503us/step - loss: 839.0408\n",
      "Epoch 228/250\n",
      "1/1 [==============================] - 0s 913us/step - loss: 836.7290\n",
      "Epoch 229/250\n",
      "1/1 [==============================] - 0s 535us/step - loss: 834.4289\n",
      "Epoch 230/250\n",
      "1/1 [==============================] - 0s 732us/step - loss: 832.1400\n",
      "Epoch 231/250\n",
      "1/1 [==============================] - 0s 497us/step - loss: 829.8625\n",
      "Epoch 232/250\n",
      "1/1 [==============================] - 0s 616us/step - loss: 827.5961\n",
      "Epoch 233/250\n",
      "1/1 [==============================] - 0s 523us/step - loss: 825.3408\n",
      "Epoch 234/250\n",
      "1/1 [==============================] - 0s 477us/step - loss: 823.0967\n",
      "Epoch 235/250\n",
      "1/1 [==============================] - 0s 731us/step - loss: 820.8633\n",
      "Epoch 236/250\n",
      "1/1 [==============================] - 0s 522us/step - loss: 818.6411\n",
      "Epoch 237/250\n",
      "1/1 [==============================] - 0s 599us/step - loss: 816.4295\n",
      "Epoch 238/250\n",
      "1/1 [==============================] - 0s 492us/step - loss: 814.2287\n",
      "Epoch 239/250\n",
      "1/1 [==============================] - 0s 719us/step - loss: 812.0385\n",
      "Epoch 240/250\n",
      "1/1 [==============================] - 0s 497us/step - loss: 809.8590\n",
      "Epoch 241/250\n",
      "1/1 [==============================] - 0s 796us/step - loss: 807.6899\n",
      "Epoch 242/250\n",
      "1/1 [==============================] - 0s 557us/step - loss: 805.5314\n",
      "Epoch 243/250\n",
      "1/1 [==============================] - 0s 753us/step - loss: 803.3831\n",
      "Epoch 244/250\n",
      "1/1 [==============================] - 0s 929us/step - loss: 801.2452\n",
      "Epoch 245/250\n",
      "1/1 [==============================] - 0s 645us/step - loss: 799.1175\n",
      "Epoch 246/250\n",
      "1/1 [==============================] - 0s 621us/step - loss: 796.9998\n",
      "Epoch 247/250\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 794.8922\n",
      "Epoch 248/250\n",
      "1/1 [==============================] - 0s 745us/step - loss: 792.7947\n",
      "Epoch 249/250\n",
      "1/1 [==============================] - 0s 791us/step - loss: 790.7072\n",
      "Epoch 250/250\n",
      "1/1 [==============================] - 0s 715us/step - loss: 788.6295\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Layer simple_dense has no inbound nodes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dd1ae426deb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunEM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclick_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_pos_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/GCM/scripts/clickmodel_fitters/GCM.py\u001b[0m in \u001b[0;36mrunEM\u001b[0;34m(click_mat, var_dic, var_models, item_order, model_def, n_jobs, max_iter, seed, tol, earlystop_patience, verbose, keras_epochs, store_best)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# # M-step (since keras already paralizes, I do not):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mvar_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGCM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimize_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/GCM/scripts/clickmodel_fitters/GCM.py\u001b[0m in \u001b[0;36m_optimize_params\u001b[0;34m(var_models, weight_dic, var_dic, verbose, epochs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0moutput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GCM/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36moutput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2103\u001b[0m     \"\"\"\n\u001b[1;32m   2104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2105\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Layer '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' has no inbound nodes.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output_tensors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Layer simple_dense has no inbound nodes."
     ]
    }
   ],
   "source": [
    "res = GCM.runEM(click_mat, var_dic, var_models, item_pos_mat, model_def, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GCM2",
   "language": "python",
   "name": "gcm2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
